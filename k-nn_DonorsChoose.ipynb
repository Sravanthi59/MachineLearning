{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource_Data_columns:\n",
      " Index(['id', 'description', 'quantity', 'price'], dtype='object')\n",
      "(1541272, 4)\n",
      "        id                                        description  quantity  \\\n",
      "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
      "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
      "\n",
      "    price  \n",
      "0  149.00  \n",
      "1   14.95  \n",
      "Train_Data_columns:\n",
      " Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
      "       'project_submitted_datetime', 'project_grade_category',\n",
      "       'project_subject_categories', 'project_subject_subcategories',\n",
      "       'project_title', 'project_essay_1', 'project_essay_2',\n",
      "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
      "       'teacher_number_of_previously_posted_projects', 'project_is_approved'],\n",
      "      dtype='object')\n",
      "(182080, 16)\n",
      "        id                        teacher_id teacher_prefix school_state  \\\n",
      "0  p036502  484aaf11257089a66cfedc9461c6bd0a            Ms.           NV   \n",
      "1  p039565  df72a3ba8089423fa8a94be88060f6ed           Mrs.           GA   \n",
      "\n",
      "  project_submitted_datetime project_grade_category  \\\n",
      "0        2016-11-18 14:45:59          Grades PreK-2   \n",
      "1        2017-04-26 15:57:28             Grades 3-5   \n",
      "\n",
      "          project_subject_categories project_subject_subcategories  \\\n",
      "0                Literacy & Language                      Literacy   \n",
      "1  Music & The Arts, Health & Sports  Performing Arts, Team Sports   \n",
      "\n",
      "              project_title  \\\n",
      "0  Super Sight Word Centers   \n",
      "1    Keep Calm and Dance On   \n",
      "\n",
      "                                     project_essay_1  \\\n",
      "0  Most of my kindergarten students come from low...   \n",
      "1  Our elementary school is a culturally rich sch...   \n",
      "\n",
      "                                     project_essay_2 project_essay_3  \\\n",
      "0  I currently have a differentiated sight word c...             NaN   \n",
      "1  We strive to provide our diverse population of...             NaN   \n",
      "\n",
      "  project_essay_4                           project_resource_summary  \\\n",
      "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
      "1             NaN  My students need matching shirts to wear for d...   \n",
      "\n",
      "   teacher_number_of_previously_posted_projects  project_is_approved  \n",
      "0                                            26                    1  \n",
      "1                                             1                    0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "resorce_data=pd.read_csv('D:\\\\resources.csv')\n",
    "train_data=pd.read_csv('D:\\\\train.csv')\n",
    "\n",
    "print(\"Resource_Data_columns:\\n\",resorce_data.columns)\n",
    "print(resorce_data.shape)\n",
    "print(resorce_data.head(2))\n",
    "print(\"Train_Data_columns:\\n\",train_data.columns)\n",
    "print(train_data.shape)\n",
    "print(train_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcesing project_grade_category  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grades PreK-2    73890\n",
      "Grades 3-5       61682\n",
      "Grades 6-8       28197\n",
      "Grades 9-12      18311\n",
      "Name: project_grade_category, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 182080/182080 [00:00<00:00, 556860.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3_5', '3_5', '3_5', '6_8']\n"
     ]
    }
   ],
   "source": [
    "print(train_data['project_grade_category'].value_counts())\n",
    "\n",
    "preprocessed_project_grade_categories= []\n",
    " \n",
    "for grade_cat in tqdm(train_data[\"project_grade_category\"]):\n",
    "    \n",
    "    grade_cat = grade_cat.replace('-', '_')  #Replacing(-) with(_)\n",
    "    grade_cat = grade_cat.replace('Grades', '') #Removing grades as it is redundant\n",
    "    #print(grade_cat)\n",
    "    grad_cat = ' '.join(f for f in grade_cat.split())\n",
    "    preprocessed_project_grade_categories.append(grad_cat.strip())\n",
    "train_data['preprocessed_project_grade_categories']=preprocessed_project_grade_categories\n",
    "print(preprocessed_project_grade_categories[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcesing project_subject_categories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>preprocessed_project_grade_categories</th>\n",
       "      <th>clean_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>484aaf11257089a66cfedc9461c6bd0a</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Super Sight Word Centers</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>I currently have a differentiated sight word c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need 6 Ipod Nano's to create and d...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>PreK_2</td>\n",
       "      <td>Literacy_Language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p039565</td>\n",
       "      <td>df72a3ba8089423fa8a94be88060f6ed</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Performing Arts, Team Sports</td>\n",
       "      <td>Keep Calm and Dance On</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>We strive to provide our diverse population of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need matching shirts to wear for d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3_5</td>\n",
       "      <td>Music_Arts Health_Sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        teacher_id teacher_prefix school_state  \\\n",
       "0  p036502  484aaf11257089a66cfedc9461c6bd0a            Ms.           NV   \n",
       "1  p039565  df72a3ba8089423fa8a94be88060f6ed           Mrs.           GA   \n",
       "\n",
       "  project_submitted_datetime project_grade_category  \\\n",
       "0        2016-11-18 14:45:59          Grades PreK-2   \n",
       "1        2017-04-26 15:57:28             Grades 3-5   \n",
       "\n",
       "  project_subject_subcategories             project_title  \\\n",
       "0                      Literacy  Super Sight Word Centers   \n",
       "1  Performing Arts, Team Sports    Keep Calm and Dance On   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Our elementary school is a culturally rich sch...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  I currently have a differentiated sight word c...             NaN   \n",
       "1  We strive to provide our diverse population of...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
       "1             NaN  My students need matching shirts to wear for d...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            26                    1   \n",
       "1                                             1                    0   \n",
       "\n",
       "  preprocessed_project_grade_categories          clean_categories  \n",
       "0                                PreK_2         Literacy_Language  \n",
       "1                                   3_5  Music_Arts Health_Sports  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catogories = list(train_data['project_subject_categories'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "cat_list = []\n",
    "for i in catogories:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n",
    "    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n",
    "        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n",
    "            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n",
    "        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n",
    "        temp+=j.strip()+\" \" #\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "        temp = temp.replace('&','_') # we are replacing the & value into \n",
    "    cat_list.append(temp.strip())\n",
    "\n",
    "train_data['clean_categories'] = cat_list\n",
    "train_data.drop(['project_subject_categories'], axis=1, inplace=True)\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Literacy_Language': 86988, 'Math_Science': 69248, 'Health_Sports': 23712, 'SpecialNeeds': 22881, 'AppliedLearning': 20303, 'Music_Arts': 17054, 'History_Civics': 9726, 'Warmth': 2327, 'Care_Hunger': 2327})\n",
      "{'Warmth': 2327, 'Care_Hunger': 2327, 'History_Civics': 9726, 'Music_Arts': 17054, 'AppliedLearning': 20303, 'SpecialNeeds': 22881, 'Health_Sports': 23712, 'Math_Science': 69248, 'Literacy_Language': 86988}\n"
     ]
    }
   ],
   "source": [
    "# count of all the words in corpus python: https://stackoverflow.com/a/22898595/4084039\n",
    "from collections import Counter\n",
    "counter = Counter()\n",
    "for word in train_data['clean_categories'].values:\n",
    "    counter.update(word.split())\n",
    "print(counter)\n",
    "\n",
    "cat_dict = dict(counter)\n",
    "sorted_cat_dict = dict(sorted(cat_dict.items(), key=lambda kv: kv[1]))\n",
    "print(sorted_cat_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcesing project_subject_subcategories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>preprocessed_project_grade_categories</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_sub_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>484aaf11257089a66cfedc9461c6bd0a</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Super Sight Word Centers</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>I currently have a differentiated sight word c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need 6 Ipod Nano's to create and d...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>PreK_2</td>\n",
       "      <td>Literacy_Language</td>\n",
       "      <td>Literacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p039565</td>\n",
       "      <td>df72a3ba8089423fa8a94be88060f6ed</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Keep Calm and Dance On</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>We strive to provide our diverse population of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need matching shirts to wear for d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3_5</td>\n",
       "      <td>Music_Arts Health_Sports</td>\n",
       "      <td>PerformingArts TeamSports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        teacher_id teacher_prefix school_state  \\\n",
       "0  p036502  484aaf11257089a66cfedc9461c6bd0a            Ms.           NV   \n",
       "1  p039565  df72a3ba8089423fa8a94be88060f6ed           Mrs.           GA   \n",
       "\n",
       "  project_submitted_datetime project_grade_category             project_title  \\\n",
       "0        2016-11-18 14:45:59          Grades PreK-2  Super Sight Word Centers   \n",
       "1        2017-04-26 15:57:28             Grades 3-5    Keep Calm and Dance On   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Our elementary school is a culturally rich sch...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  I currently have a differentiated sight word c...             NaN   \n",
       "1  We strive to provide our diverse population of...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
       "1             NaN  My students need matching shirts to wear for d...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            26                    1   \n",
       "1                                             1                    0   \n",
       "\n",
       "  preprocessed_project_grade_categories          clean_categories  \\\n",
       "0                                PreK_2         Literacy_Language   \n",
       "1                                   3_5  Music_Arts Health_Sports   \n",
       "\n",
       "        clean_sub_categories  \n",
       "0                   Literacy  \n",
       "1  PerformingArts TeamSports  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_catogories = list(train_data['project_subject_subcategories'].values)\n",
    "# remove special characters from list of strings python: https://stackoverflow.com/a/47301924/4084039\n",
    "\n",
    "# https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "# https://stackoverflow.com/questions/23669024/how-to-strip-a-specific-word-from-a-string\n",
    "# https://stackoverflow.com/questions/8270092/remove-all-whitespace-in-a-string-in-python\n",
    "\n",
    "sub_cat_list = []\n",
    "for i in sub_catogories:\n",
    "    temp = \"\"\n",
    "    # consider we have text like this \"Math & Science, Warmth, Care & Hunger\"\n",
    "    for j in i.split(','): # it will split it in three parts [\"Math & Science\", \"Warmth\", \"Care & Hunger\"]\n",
    "        if 'The' in j.split(): # this will split each of the catogory based on space \"Math & Science\"=> \"Math\",\"&\", \"Science\"\n",
    "            j=j.replace('The','') # if we have the words \"The\" we are going to replace it with ''(i.e removing 'The')\n",
    "        j = j.replace(' ','') # we are placeing all the ' '(space) with ''(empty) ex:\"Math & Science\"=>\"Math&Science\"\n",
    "        temp +=j.strip()+\" \"#\" abc \".strip() will return \"abc\", remove the trailing spaces\n",
    "        temp = temp.replace('&','_')\n",
    "    sub_cat_list.append(temp.strip())\n",
    "    \n",
    "train_data['clean_sub_categories'] = sub_cat_list\n",
    "#train_data.head(10)\n",
    "train_data.drop(['project_subject_subcategories'], axis=1, inplace=True)\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Literacy': 56066, 'Mathematics': 46884, 'Literature_Writing': 36974, 'SpecialNeeds': 22881, 'AppliedSciences': 17966, 'Health_Wellness': 17099, 'VisualArts': 10399, 'EnvironmentalScience': 9436, 'Gym_Fitness': 7592, 'Health_LifeScience': 7175, 'ESL': 7162, 'EarlyDevelopment': 7149, 'History_Geography': 5258, 'Music': 5172, 'College_CareerPrep': 4291, 'Other': 3948, 'TeamSports': 3643, 'CharacterEducation': 3519, 'PerformingArts': 3223, 'SocialSciences': 3149, 'Warmth': 2327, 'Care_Hunger': 2327, 'NutritionEducation': 2236, 'ForeignLanguages': 1496, 'Extracurricular': 1332, 'Civics_Government': 1294, 'ParentInvolvement': 1103, 'FinancialLiteracy': 956, 'CommunityService': 712, 'Economics': 431})\n",
      "{'Economics': 431, 'CommunityService': 712, 'FinancialLiteracy': 956, 'ParentInvolvement': 1103, 'Civics_Government': 1294, 'Extracurricular': 1332, 'ForeignLanguages': 1496, 'NutritionEducation': 2236, 'Warmth': 2327, 'Care_Hunger': 2327, 'SocialSciences': 3149, 'PerformingArts': 3223, 'CharacterEducation': 3519, 'TeamSports': 3643, 'Other': 3948, 'College_CareerPrep': 4291, 'Music': 5172, 'History_Geography': 5258, 'EarlyDevelopment': 7149, 'ESL': 7162, 'Health_LifeScience': 7175, 'Gym_Fitness': 7592, 'EnvironmentalScience': 9436, 'VisualArts': 10399, 'Health_Wellness': 17099, 'AppliedSciences': 17966, 'SpecialNeeds': 22881, 'Literature_Writing': 36974, 'Mathematics': 46884, 'Literacy': 56066}\n"
     ]
    }
   ],
   "source": [
    "my_counter = Counter()\n",
    "for word in train_data['clean_sub_categories'].values:\n",
    "    my_counter.update(word.split())\n",
    "print(my_counter)\n",
    "\n",
    "sub_cat_dict = dict(my_counter)\n",
    "sorted_sub_cat_dict = dict(sorted(sub_cat_dict.items(), key=lambda kv: kv[1]))\n",
    "print(sorted_sub_cat_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcesing teacher_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 182080/182080 [00:00<00:00, 2092463.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Mrs        95405\n",
       "Ms         65066\n",
       "Mr         17667\n",
       "Teacher     3912\n",
       "Dr            26\n",
       "null           4\n",
       "Name: teacher_prefix, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['teacher_prefix'] = train_data['teacher_prefix'].fillna('null')\n",
    "\n",
    "def replace_dot(strval):          # Removing (.) in Mrs. \n",
    "    return strval.replace('.','')\n",
    "   \n",
    "\n",
    "train_data['teacher_prefix']= train_data['teacher_prefix'].astype(str).apply(replace_dot)\n",
    "\n",
    "preprocessed_teacher_prefix = []\n",
    "\n",
    "for teach_prefix in tqdm(train_data[\"teacher_prefix\"]):\n",
    "    \n",
    "    preprocessed_teacher_prefix.append(teach_prefix.strip())\n",
    "    \n",
    "train_data.teacher_prefix.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a new feature Number of words in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>preprocessed_project_grade_categories</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_sub_categories</th>\n",
       "      <th>title_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>484aaf11257089a66cfedc9461c6bd0a</td>\n",
       "      <td>Ms</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Super Sight Word Centers</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>I currently have a differentiated sight word c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need 6 Ipod Nano's to create and d...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>PreK_2</td>\n",
       "      <td>Literacy_Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p039565</td>\n",
       "      <td>df72a3ba8089423fa8a94be88060f6ed</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Keep Calm and Dance On</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>We strive to provide our diverse population of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need matching shirts to wear for d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3_5</td>\n",
       "      <td>Music_Arts Health_Sports</td>\n",
       "      <td>PerformingArts TeamSports</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        teacher_id teacher_prefix school_state  \\\n",
       "0  p036502  484aaf11257089a66cfedc9461c6bd0a             Ms           NV   \n",
       "1  p039565  df72a3ba8089423fa8a94be88060f6ed            Mrs           GA   \n",
       "\n",
       "  project_submitted_datetime project_grade_category             project_title  \\\n",
       "0        2016-11-18 14:45:59          Grades PreK-2  Super Sight Word Centers   \n",
       "1        2017-04-26 15:57:28             Grades 3-5    Keep Calm and Dance On   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Our elementary school is a culturally rich sch...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  I currently have a differentiated sight word c...             NaN   \n",
       "1  We strive to provide our diverse population of...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
       "1             NaN  My students need matching shirts to wear for d...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            26                    1   \n",
       "1                                             1                    0   \n",
       "\n",
       "  preprocessed_project_grade_categories          clean_categories  \\\n",
       "0                                PreK_2         Literacy_Language   \n",
       "1                                   3_5  Music_Arts Health_Sports   \n",
       "\n",
       "        clean_sub_categories  title_word_count  \n",
       "0                   Literacy                 4  \n",
       "1  PerformingArts TeamSports                 5  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_word_count = []\n",
    "\n",
    "for title in train_data[\"project_title\"] :\n",
    "    length = len(title.split())\n",
    "    title_word_count.append(length)\n",
    "\n",
    "train_data[\"title_word_count\"] = title_word_count\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging project_essays into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>preprocessed_project_grade_categories</th>\n",
       "      <th>clean_categories</th>\n",
       "      <th>clean_sub_categories</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>essay</th>\n",
       "      <th>essay_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>484aaf11257089a66cfedc9461c6bd0a</td>\n",
       "      <td>Ms</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:59</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Super Sight Word Centers</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>I currently have a differentiated sight word c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need 6 Ipod Nano's to create and d...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>PreK_2</td>\n",
       "      <td>Literacy_Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>4</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p039565</td>\n",
       "      <td>df72a3ba8089423fa8a94be88060f6ed</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:28</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Keep Calm and Dance On</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>We strive to provide our diverse population of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need matching shirts to wear for d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3_5</td>\n",
       "      <td>Music_Arts Health_Sports</td>\n",
       "      <td>PerformingArts TeamSports</td>\n",
       "      <td>5</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                        teacher_id teacher_prefix school_state  \\\n",
       "0  p036502  484aaf11257089a66cfedc9461c6bd0a             Ms           NV   \n",
       "1  p039565  df72a3ba8089423fa8a94be88060f6ed            Mrs           GA   \n",
       "\n",
       "  project_submitted_datetime project_grade_category             project_title  \\\n",
       "0        2016-11-18 14:45:59          Grades PreK-2  Super Sight Word Centers   \n",
       "1        2017-04-26 15:57:28             Grades 3-5    Keep Calm and Dance On   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Our elementary school is a culturally rich sch...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  I currently have a differentiated sight word c...             NaN   \n",
       "1  We strive to provide our diverse population of...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
       "1             NaN  My students need matching shirts to wear for d...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  \\\n",
       "0                                            26                    1   \n",
       "1                                             1                    0   \n",
       "\n",
       "  preprocessed_project_grade_categories          clean_categories  \\\n",
       "0                                PreK_2         Literacy_Language   \n",
       "1                                   3_5  Music_Arts Health_Sports   \n",
       "\n",
       "        clean_sub_categories  title_word_count  \\\n",
       "0                   Literacy                 4   \n",
       "1  PerformingArts TeamSports                 5   \n",
       "\n",
       "                                               essay  essay_word_count  \n",
       "0  Most of my kindergarten students come from low...               311  \n",
       "1  Our elementary school is a culturally rich sch...               189  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge four column essay text dataframe: \n",
    "train_data['essay'] = train_data['project_essay_1'].map(str) +\\\n",
    "                        train_data['project_essay_2'].map(str) + \\\n",
    "                        train_data['project_essay_3'].map(str) + \\\n",
    "                        train_data['project_essay_4'].map(str)\n",
    "\n",
    "#Adding a new feature Number of words in essay\n",
    "essay_word_count=[]\n",
    "\n",
    "for essay in train_data[\"essay\"] :\n",
    "    length = len(essay.split())\n",
    "    essay_word_count.append(length)\n",
    "    \n",
    "train_data[\"essay_word_count\"] = essay_word_count\n",
    "\n",
    "train_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train ,Test  Data spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python1\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# train test split using sklearn.model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_data['project_is_approved'], test_size=0.33, stratify = train_data['project_is_approved'],random_state=0)\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.33, stratify=y_train,random_state=0)\n",
    "\n",
    "X_train.drop(['project_is_approved'], axis=1, inplace=True)\n",
    "X_test.drop(['project_is_approved'], axis=1, inplace=True)\n",
    "X_cv.drop(['project_is_approved'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most of my kindergarten students come from low-income households and are considered \\\"at-risk\\\". These kids walk to school alongside their parents and most have never been further than walking distance from their house. For 80% of my students, English is not their first language or the language spoken at home. \\r\\n\\r\\nWhile my kindergarten kids have many obstacles in front of them, they come to school each day excited and ready to learn. Most students started the year out never being in a school setting. At the start of the year many had never been exposed to letters. Each day they soak up more knowledge and try their hardest to succeed. They are highly motivated to learn new things every day. We are halfway through the year and they are starting to take off. They know know all letters, some sight words, numbers to 20, and a majority of their letter sounds because of their hard work and determination. I am excited to see the places we will go from here!I currently have a differentiated sight word center that we do daily during our literacy stations. The students have activities that relate to whatever sight word list they are on. This is one of their favorite station activities. I want to continue to provide the students with engaging ways to practice their sight words. \\r\\n\\r\\nI dream of having the students use QR readers to scan the sight words that they are struggling with and the Ipods reading the sight words with them. This would help so many of my students by giving them multiple exposures to the words. My students need someone who can go over these sight words daily and I can't always get around to everyone to practice their flashcards with them. With the Ipods they would still have a way to practice their sight words on a daily basis.nannan\n",
      "Most of my kindergarten students come from low-income households and are considered \\\"at-risk\\\". These kids walk to school alongside their parents and most have never been further than walking distance from their house. For 80% of my students, English is not their first language or the language spoken at home. \\r\\n\\r\\nWhile my kindergarten kids have many obstacles in front of them, they come to school each day excited and ready to learn. Most students started the year out never being in a school setting. At the start of the year many had never been exposed to letters. Each day they soak up more knowledge and try their hardest to succeed. They are highly motivated to learn new things every day. We are halfway through the year and they are starting to take off. They know know all letters, some sight words, numbers to 20, and a majority of their letter sounds because of their hard work and determination. I am excited to see the places we will go from here!I currently have a differentiated sight word center that we do daily during our literacy stations. The students have activities that relate to whatever sight word list they are on. This is one of their favorite station activities. I want to continue to provide the students with engaging ways to practice their sight words. \\r\\n\\r\\nI dream of having the students use QR readers to scan the sight words that they are struggling with and the Ipods reading the sight words with them. This would help so many of my students by giving them multiple exposures to the words. My students need someone who can go over these sight words daily and I can not always get around to everyone to practice their flashcards with them. With the Ipods they would still have a way to practice their sight words on a daily basis.nannan\n",
      "______________________________________________________________________________________________________________\n",
      "Most of my kindergarten students come from low-income households and are considered  at-risk . These kids walk to school alongside their parents and most have never been further than walking distance from their house. For 80% of my students, English is not their first language or the language spoken at home.     While my kindergarten kids have many obstacles in front of them, they come to school each day excited and ready to learn. Most students started the year out never being in a school setting. At the start of the year many had never been exposed to letters. Each day they soak up more knowledge and try their hardest to succeed. They are highly motivated to learn new things every day. We are halfway through the year and they are starting to take off. They know know all letters, some sight words, numbers to 20, and a majority of their letter sounds because of their hard work and determination. I am excited to see the places we will go from here!I currently have a differentiated sight word center that we do daily during our literacy stations. The students have activities that relate to whatever sight word list they are on. This is one of their favorite station activities. I want to continue to provide the students with engaging ways to practice their sight words.     I dream of having the students use QR readers to scan the sight words that they are struggling with and the Ipods reading the sight words with them. This would help so many of my students by giving them multiple exposures to the words. My students need someone who can go over these sight words daily and I can not always get around to everyone to practice their flashcards with them. With the Ipods they would still have a way to practice their sight words on a daily basis.nannan\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/a/47091490/4084039\n",
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "\n",
    "print(train_data['essay'].values[0])\n",
    "\n",
    "sent = decontracted(train_data['essay'].values[0])\n",
    "print(sent)\n",
    "print(\"___________\"*10)\n",
    "sent = sent.replace('\\\\r', ' ')\n",
    "sent = sent.replace('\\\\\"', ' ')\n",
    "sent = sent.replace('\\\\n', ' ')\n",
    "print(sent)\n",
    "\n",
    "sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gist.github.com/sebleier/554280\n",
    "# we are removing the words from the stop words list: 'no', 'nor', 'not'\n",
    "stopwords= ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "            \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "            'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "            'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "            'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "            'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "            'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "            'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "            'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "            'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "            's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "            've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "            \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "            \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "            'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing X_train['essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 81735/81735 [00:44<00:00, 1825.93it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preprocessed_essays_train = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(X_train['essay'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    preprocessed_essays_train.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing X_test['essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 60087/60087 [00:33<00:00, 1769.76it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_essays_test = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(X_test['essay'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    preprocessed_essays_test.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing X_cv['essay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 40258/40258 [00:22<00:00, 1785.68it/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_essays_cv = []\n",
    "# tqdm is for printing the status bar\n",
    "for sentance in tqdm(X_cv['essay'].values):\n",
    "    sent = decontracted(sentance)\n",
    "    sent = sent.replace('\\\\r', ' ')\n",
    "    sent = sent.replace('\\\\\"', ' ')\n",
    "    sent = sent.replace('\\\\n', ' ')\n",
    "    sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
    "    # https://gist.github.com/sebleier/554280\n",
    "    sent = ' '.join(e for e in sent.split() if e not in stopwords)\n",
    "    preprocessed_essays_cv.append(sent.lower().strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing project title(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to Reach Our Virtual  Mentors!!!\n",
      "classroom supplies room 205\n"
     ]
    }
   ],
   "source": [
    "print(train_data['project_title'].values[5])\n",
    "preprocessed_project_title_train=[]\n",
    "\n",
    "for title in (X_train['project_title'].values):\n",
    "    tilte =decontracted(title)\n",
    "    title = title.replace('\\\\r', ' ')\n",
    "    title = title.replace('\\\\\"', ' ')\n",
    "    title = title.replace('\\\\n', ' ')\n",
    "    title = re.sub('[^A-Za-z0-9]+', ' ', title)\n",
    "    title =' '.join(word for word in title.split() if word not in stopwords)\n",
    "    preprocessed_project_title_train.append(title.lower().strip())\n",
    "print(preprocessed_project_title_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing project title(Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picture this\n"
     ]
    }
   ],
   "source": [
    "preprocessed_project_title_test=[]\n",
    "\n",
    "for title in (X_test['project_title'].values):\n",
    "    tilte =decontracted(title)\n",
    "    title = title.replace('\\\\r', ' ')\n",
    "    title = title.replace('\\\\\"', ' ')\n",
    "    title = title.replace('\\\\n', ' ')\n",
    "    title = re.sub('[^A-Za-z0-9]+', ' ', title)\n",
    "    title =' '.join(word for word in title.split() if word not in stopwords)\n",
    "    preprocessed_project_title_test.append(title.lower().strip())\n",
    "print(preprocessed_project_title_test[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing project title(CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art plus math equals interactive notebooks\n"
     ]
    }
   ],
   "source": [
    "preprocessed_project_title_cv=[]\n",
    "\n",
    "for title in (X_cv['project_title'].values):\n",
    "    tilte =decontracted(title)\n",
    "    title = title.replace('\\\\r', ' ')\n",
    "    title = title.replace('\\\\\"', ' ')\n",
    "    title = title.replace('\\\\n', ' ')\n",
    "    title = re.sub('[^A-Za-z0-9]+', ' ', title)\n",
    "    title =' '.join(word for word in title.split() if word not in stopwords)\n",
    "    preprocessed_project_title_cv.append(title.lower().strip())\n",
    "print(preprocessed_project_title_cv[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding for clean_categories of Projects (train,test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Warmth', 'Care_Hunger', 'History_Civics', 'Music_Arts', 'AppliedLearning', 'SpecialNeeds', 'Health_Sports', 'Math_Science', 'Literacy_Language']\n",
      "Shape of matrix after one hot encodig  (81735, 9)\n",
      "Shape of matrix after one hot encodig  (60087, 9)\n",
      "Shape of matrix after one hot encodig  (40258, 9)\n"
     ]
    }
   ],
   "source": [
    "# we use count vectorizer to convert the values into one hot encoded features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=list(sorted_cat_dict.keys()), lowercase=False, binary=True)\n",
    "vectorizer.fit(train_data['clean_categories'].values)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "categories_one_hot_train = vectorizer.transform(X_train['clean_categories'].values)\n",
    "categories_one_hot_test = vectorizer.transform(X_test['clean_categories'].values)\n",
    "categories_one_hot_cv = vectorizer.transform(X_cv['clean_categories'].values)\n",
    "\n",
    "print(\"Shape of matrix after one hot encodig \",categories_one_hot_train.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",categories_one_hot_test.shape)\n",
    "print(\"Shape of matrix after one hot encodig \",categories_one_hot_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding for clean_sub_categories of Projects (train,test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Economics', 'CommunityService', 'FinancialLiteracy', 'ParentInvolvement', 'Civics_Government', 'Extracurricular', 'ForeignLanguages', 'NutritionEducation', 'Warmth', 'Care_Hunger', 'SocialSciences', 'PerformingArts', 'CharacterEducation', 'TeamSports', 'Other', 'College_CareerPrep', 'Music', 'History_Geography', 'EarlyDevelopment', 'ESL', 'Health_LifeScience', 'Gym_Fitness', 'EnvironmentalScience', 'VisualArts', 'Health_Wellness', 'AppliedSciences', 'SpecialNeeds', 'Literature_Writing', 'Mathematics', 'Literacy']\n",
      "Shape of matrix of Train data after one hot encoding  (81735, 30)\n",
      "Shape of matrix of Test data after one hot encoding  (60087, 30)\n",
      "Shape of matrix of Cross Validation data after one hot encoding  (40258, 30)\n"
     ]
    }
   ],
   "source": [
    "# we use count vectorizer to convert the values into one \n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=list(sorted_sub_cat_dict.keys()), lowercase=False, binary=True)\n",
    "vectorizer.fit(train_data['clean_sub_categories'].values)\n",
    "\n",
    "sub_categories_one_hot_train = vectorizer.transform(X_train['clean_sub_categories'].values)\n",
    "sub_categories_one_hot_test = vectorizer.transform(X_test['clean_sub_categories'].values)\n",
    "sub_categories_one_hot_cv = vectorizer.transform(X_cv['clean_sub_categories'].values)\n",
    "\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "print(\"Shape of matrix of Train data after one hot encoding \",sub_categories_one_hot_train.shape)\n",
    "print(\"Shape of matrix of Test data after one hot encoding \",sub_categories_one_hot_test.shape)\n",
    "print(\"Shape of matrix of Cross Validation data after one hot encoding \",sub_categories_one_hot_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding for school_state of Projects (train,test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VT', 'WY', 'ND', 'MT', 'RI', 'NE', 'SD', 'AK', 'NH', 'DE', 'ME', 'WV', 'HI', 'DC', 'NM', 'KS', 'IA', 'ID', 'AR', 'CO', 'MN', 'OR', 'KY', 'MS', 'NV', 'MD', 'CT', 'UT', 'TN', 'AL', 'WI', 'VA', 'AZ', 'NJ', 'OK', 'WA', 'LA', 'MA', 'OH', 'MO', 'IN', 'PA', 'MI', 'SC', 'GA', 'IL', 'NC', 'FL', 'NY', 'TX', 'CA']\n",
      "Shape of matrix of Train data after one hot encoding  (81735, 51)\n",
      "Shape of matrix of Test data after one hot encoding  (60087, 51)\n",
      "Shape of matrix of Cross Validation data after one hot encoding  (40258, 51)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#One Hot Encode - School States\n",
    "my_counter = Counter()\n",
    "for state in train_data['school_state'].values:\n",
    "    my_counter.update(state.split())\n",
    "\n",
    "school_state_cat_dict = dict(my_counter)\n",
    "sorted_school_state_cat_dict = dict(sorted(school_state_cat_dict.items(), key=lambda kv: kv[1]))\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=list(sorted_school_state_cat_dict.keys()), lowercase=False, binary=True)\n",
    "vectorizer.fit(train_data['school_state'].values)\n",
    "\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "school_state_categories_one_hot_train = vectorizer.transform(X_train['school_state'].values)\n",
    "school_state_categories_one_hot_test = vectorizer.transform(X_test['school_state'].values)\n",
    "school_state_categories_one_hot_cv = vectorizer.transform(X_cv['school_state'].values)\n",
    "\n",
    "print(\"Shape of matrix of Train data after one hot encoding \",school_state_categories_one_hot_train.shape)\n",
    "print(\"Shape of matrix of Test data after one hot encoding \",school_state_categories_one_hot_test.shape)\n",
    "print(\"Shape of matrix of Cross Validation data after one hot encoding \",school_state_categories_one_hot_cv.shape)\n",
    "\n",
    "school_state_categories_one_hot_train.toarray()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding for project_grade_category of Projects (train,test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9_12', '6_8', '3_5', 'PreK_2']\n",
      "Shape of matrix of Train data after one hot encoding  (81735, 4)\n",
      "Shape of matrix of Test data after one hot encoding  (60087, 4)\n",
      "Shape of matrix of Cross Validation data after one hot encoding  (40258, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#One Hot Encode - Project Grade Category\n",
    "my_counter = Counter()\n",
    "for project_grade in train_data['preprocessed_project_grade_categories'].values:\n",
    "    my_counter.update(project_grade.split())\n",
    "    \n",
    "project_grade_cat_dict = dict(my_counter)\n",
    "sorted_project_grade_cat_dict = dict(sorted(project_grade_cat_dict.items(), key=lambda kv: kv[1]))\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary=list(sorted_project_grade_cat_dict.keys()), lowercase=False, binary=True)\n",
    "vectorizer.fit(train_data['preprocessed_project_grade_categories'].values)\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "project_grade_categories_one_hot_train = vectorizer.transform(X_train['preprocessed_project_grade_categories'].values)\n",
    "project_grade_categories_one_hot_test = vectorizer.transform(X_test['preprocessed_project_grade_categories'].values)\n",
    "project_grade_categories_one_hot_cv = vectorizer.transform(X_cv['preprocessed_project_grade_categories'].values)\n",
    "\n",
    "print(\"Shape of matrix of Train data after one hot encoding \",project_grade_categories_one_hot_train.shape)\n",
    "print(\"Shape of matrix of Test data after one hot encoding \",project_grade_categories_one_hot_test.shape)\n",
    "print(\"Shape of matrix of Cross Validation data after one hot encoding \",project_grade_categories_one_hot_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one hot encoding for teacher_prefix of Projects (train,test,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dr', 'mr', 'mrs', 'ms', 'null', 'teacher']\n",
      "After vectorizations\n",
      "Shape of matrix of Train data after one hot encoding (81735, 6) (81735,)\n",
      "Shape of matrix of cv data after one hot encoding (40258, 6) (40258,)\n",
      "Shape of matrix of Test data after one hot encoding (60087, 6) (60087,)\n"
     ]
    }
   ],
   "source": [
    "#One Hot Encode - Teacher Prefix\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_train['teacher_prefix'].values)\n",
    "print(vectorizer.get_feature_names())\n",
    "\n",
    "# we use the fitted CountVectorizer to convert the text to vector\n",
    "teacher_prefix_categories_one_hot_train = vectorizer.transform(X_train['teacher_prefix'].values)\n",
    "teacher_prefix_categories_one_hot_cv = vectorizer.transform(X_cv['teacher_prefix'].values)\n",
    "teacher_prefix_categories_one_hot_test = vectorizer.transform(X_test['teacher_prefix'].values)\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(\"Shape of matrix of Train data after one hot encoding\",teacher_prefix_categories_one_hot_train.shape, y_train.shape)\n",
    "print(\"Shape of matrix of cv data after one hot encoding\",teacher_prefix_categories_one_hot_cv.shape, y_cv.shape)\n",
    "print(\"Shape of matrix of Test data after one hot encoding\",teacher_prefix_categories_one_hot_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing BOW(preprocessed_essays_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig train  (81735, 5000)\n"
     ]
    }
   ],
   "source": [
    "# We are considering only the words which appeared in at least 10 documents(rows or projects).\n",
    "vectorizer = CountVectorizer(min_df=10,max_features=5000)\n",
    "text_bow_train = vectorizer.fit_transform(preprocessed_essays_train)\n",
    "print(\"Shape of matrix after one hot encodig train \",text_bow_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW(preprocessed_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig test   (60087, 5000)\n"
     ]
    }
   ],
   "source": [
    "# We are considering only the words which appeared in at least 10 documents(rows or projects).\n",
    "vectorizer = CountVectorizer(min_df=10,max_features=5000)\n",
    "text_bow_test = vectorizer.fit_transform(preprocessed_essays_test)\n",
    "print(\"Shape of matrix after one hot encodig test  \",text_bow_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOWpreprocessed_essays_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encodig cv  (40258, 5000)\n"
     ]
    }
   ],
   "source": [
    "# We are considering only the words which appeared in at least 10 documents(rows or projects).\n",
    "vectorizer = CountVectorizer(min_df=10,max_features=5000)\n",
    "text_bow_cv = vectorizer.fit_transform(preprocessed_essays_cv)\n",
    "print(\"Shape of matrix after one hot encodig cv \",text_bow_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW(preprocessed_titles_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encoding  (81735, 5000)\n"
     ]
    }
   ],
   "source": [
    "# vectorizer.fit(preprocessed_titles_train)\n",
    "title_bow_train = vectorizer.transform(preprocessed_project_title_train)\n",
    "print(\"Shape of matrix after one hot encoding \",title_bow_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW(preprocessed_titles_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encoding  (60087, 5000)\n"
     ]
    }
   ],
   "source": [
    "title_bow_test = vectorizer.transform(preprocessed_project_title_test)\n",
    "print(\"Shape of matrix after one hot encoding \",title_bow_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW(preprocessed_titles_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encoding  (40258, 5000)\n"
     ]
    }
   ],
   "source": [
    "title_bow_cv = vectorizer.transform(preprocessed_project_title_cv)\n",
    "print(\"Shape of matrix after one hot encoding \",title_bow_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF(preprocessed_essays_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encoding  (81735, 5000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=10,max_features=5000) #Considering top 5000 features\n",
    "vectorizer.fit(preprocessed_essays_train)\n",
    "\n",
    "text_tfidf_train = vectorizer.transform(preprocessed_essays_train)\n",
    "print(\"Shape of matrix after one hot encoding \",text_tfidf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF(preprocessed_essays_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encoding  (60087, 5000)\n"
     ]
    }
   ],
   "source": [
    "text_tfidf_test = vectorizer.transform(preprocessed_essays_test)\n",
    "print(\"Shape of matrix after one hot encoding \",text_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF(preprocessed_essays_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encoding  (40258, 5000)\n"
     ]
    }
   ],
   "source": [
    "text_tfidf_cv = vectorizer.transform(preprocessed_essays_cv)\n",
    "print(\"Shape of matrix after one hot encoding \",text_tfidf_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF(preprocessed_project_title_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encoding  (81735, 2784)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=10)\n",
    "\n",
    "vectorizer.fit(preprocessed_project_title_train)\n",
    "title_tfidf_train = vectorizer.transform(preprocessed_project_title_train)\n",
    "print(\"Shape of matrix after one hot encoding \",title_tfidf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF(preprocessed_project_title_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encoding  (60087, 2784)\n"
     ]
    }
   ],
   "source": [
    "title_tfidf_test = vectorizer.transform(preprocessed_project_title_test)\n",
    "print(\"Shape of matrix after one hot encoding \",title_tfidf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF(preprocessed_project_title_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of matrix after one hot encoding  (40258, 2784)\n"
     ]
    }
   ],
   "source": [
    "title_tfidf_cv = vectorizer.transform(preprocessed_project_title_cv)\n",
    "print(\"Shape of matrix after one hot encoding \",title_tfidf_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadGloveModel(gloveFile):\n",
    "    \n",
    "    print (\"Loading Glove Model\")\n",
    "    \n",
    "    f = open(gloveFile,'r', encoding = 'utf8')\n",
    "    \n",
    "    model = {}\n",
    "    \n",
    "    for line in tqdm(f):\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    \n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Glove Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1917494it [04:29, 7103.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. 1917494  words loaded!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = loadGloveModel('D:\\\\glove.42B.300d.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizing Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                        description  quantity  \\\n",
      "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
      "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
      "2  p069063  Cory Stories: A Kid's Book About Living With Adhd         1   \n",
      "\n",
      "    price  \n",
      "0  149.00  \n",
      "1   14.95  \n",
      "2    8.45  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>459.56</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>515.89</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p000003</td>\n",
       "      <td>298.97</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   price  quantity\n",
       "0  p000001  459.56         7\n",
       "1  p000002  515.89        21\n",
       "2  p000003  298.97         4"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(resorce_data.head(3))\n",
    "\n",
    "price_data = resorce_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
    "price_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join two dataframes in python: \n",
    "X_train = pd.merge(X_train, price_data, on='id', how='left')\n",
    "X_test = pd.merge(X_test, price_data, on='id', how='left')\n",
    "X_cv = pd.merge(X_cv, price_data, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(81735, 1) (81735,)\n",
      "(40258, 1) (40258,)\n",
      "(60087, 1) (60087,)\n",
      "====================================================================================================\n",
      "[[-0.64895639]\n",
      " [-0.73455901]\n",
      " [-0.04759115]\n",
      " [-0.51971001]\n",
      " [ 0.41224441]\n",
      " [ 0.59722761]\n",
      " [-0.77899085]\n",
      " [-0.74542919]\n",
      " [-0.55166832]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "normalizer = StandardScaler()\n",
    "\n",
    "# normalizer.fit(X_train['price'].values)\n",
    "# this will rise an error Expected 2D array, got 1D array instead: \n",
    "# array=[105.22 215.96  96.01 ... 368.98  80.53 709.67].\n",
    "# Reshape your data either using \n",
    "# array.reshape(-1, 1) if your data has a single feature \n",
    "# array.reshape(1, -1)  if it contains a single sample.\n",
    "\n",
    "normalizer.fit(X_train['price'].values.reshape(-1,1))\n",
    "\n",
    "price_train = normalizer.transform(X_train['price'].values.reshape(-1,1))\n",
    "price_cv = normalizer.transform(X_cv['price'].values.reshape(-1,1))\n",
    "price_test = normalizer.transform(X_test['price'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(price_train.shape, y_train.shape)\n",
    "print(price_cv.shape, y_cv.shape)\n",
    "print(price_test.shape, y_test.shape)\n",
    "print(\"=\"*100)\n",
    "print(price_test[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(81735, 1) (81735,)\n",
      "(40258, 1) (40258,)\n",
      "(60087, 1) (60087,)\n",
      "====================================================================================================\n",
      "[[-0.38073587]\n",
      " [-0.41926325]\n",
      " [-0.496318  ]\n",
      " [-0.53484537]\n",
      " [-0.61190012]\n",
      " [-0.38073587]\n",
      " [ 1.85385186]\n",
      " [ 0.04306525]\n",
      " [ 0.89066749]]\n"
     ]
    }
   ],
   "source": [
    "normalizer = StandardScaler()\n",
    "\n",
    "# normalizer.fit(X_train['price'].values)\n",
    "# this will rise an error Expected 2D array, got 1D array instead: \n",
    "# array=[105.22 215.96  96.01 ... 368.98  80.53 709.67].\n",
    "# Reshape your data either using \n",
    "# array.reshape(-1, 1) if your data has a single feature \n",
    "# array.reshape(1, -1)  if it contains a single sample.\n",
    "\n",
    "normalizer.fit(X_train['quantity'].values.reshape(-1,1))\n",
    "\n",
    "quantity_train = normalizer.transform(X_train['quantity'].values.reshape(-1,1))\n",
    "quantity_cv = normalizer.transform(X_cv['quantity'].values.reshape(-1,1))\n",
    "quantity_test = normalizer.transform(X_test['quantity'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(quantity_train.shape, y_train.shape)\n",
    "print(quantity_cv.shape, y_cv.shape)\n",
    "print(quantity_test.shape, y_test.shape)\n",
    "print(\"=\"*100)\n",
    "print(quantity_test[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(81735, 1) (81735,)\n",
      "(40258, 1) (40258,)\n",
      "(60087, 1) (60087,)\n",
      "====================================================================================================\n",
      "[-0.11496503]\n"
     ]
    }
   ],
   "source": [
    "normalizer = StandardScaler()\n",
    "\n",
    "# normalizer.fit(X_train['price'].values)\n",
    "# this will rise an error Expected 2D array, got 1D array instead: \n",
    "# array=[105.22 215.96  96.01 ... 368.98  80.53 709.67].\n",
    "# Reshape your data either using \n",
    "# array.reshape(-1, 1) if your data has a single feature \n",
    "# array.reshape(1, -1)  if it contains a single sample.\n",
    "\n",
    "normalizer.fit(X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "\n",
    "prev_projects_train = normalizer.transform(X_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "prev_projects_cv = normalizer.transform(X_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "prev_projects_test = normalizer.transform(X_test['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(prev_projects_train.shape, y_train.shape)\n",
    "print(prev_projects_cv.shape, y_cv.shape)\n",
    "print(prev_projects_test.shape, y_test.shape)\n",
    "print(\"=\"*100)\n",
    "print(prev_projects_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(81735, 1) (81735,)\n",
      "(40258, 1) (40258,)\n",
      "(60087, 1) (60087,)\n",
      "====================================================================================================\n",
      "[[ 0.40944496]\n",
      " [-0.54117169]\n",
      " [ 0.88475328]\n",
      " [-0.54117169]\n",
      " [-0.06586336]\n",
      " [ 0.40944496]\n",
      " [-1.01648001]\n",
      " [-1.01648001]\n",
      " [-0.54117169]]\n"
     ]
    }
   ],
   "source": [
    "normalizer = StandardScaler()\n",
    "\n",
    "normalizer.fit(X_train['title_word_count'].values.reshape(-1,1))\n",
    "\n",
    "title_word_count_train = normalizer.transform(X_train['title_word_count'].values.reshape(-1,1))\n",
    "title_word_count_cv = normalizer.transform(X_cv['title_word_count'].values.reshape(-1,1))\n",
    "title_word_count_test = normalizer.transform(X_test['title_word_count'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(title_word_count_train.shape, y_train.shape)\n",
    "print(title_word_count_cv.shape, y_cv.shape)\n",
    "print(title_word_count_test.shape, y_test.shape)\n",
    "print(\"=\"*100)\n",
    "print(title_word_count_train[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "D:\\Python1\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After vectorizations\n",
      "(81735, 1) (81735,)\n",
      "(40258, 1) (40258,)\n",
      "(60087, 1) (60087,)\n",
      "[[ 0.15438296]\n",
      " [-0.39618138]\n",
      " [ 0.67436038]\n",
      " [-0.80910463]\n",
      " [ 0.68965384]\n",
      " [-0.90086535]\n",
      " [-0.97733262]\n",
      " [-1.14556061]\n",
      " [ 0.64377348]]\n"
     ]
    }
   ],
   "source": [
    "normalizer = StandardScaler()\n",
    "\n",
    "normalizer.fit(X_train['essay_word_count'].values.reshape(-1,1))\n",
    "\n",
    "essay_word_count_train = normalizer.transform(X_train['essay_word_count'].values.reshape(-1,1))\n",
    "essay_word_count_cv = normalizer.transform(X_cv['essay_word_count'].values.reshape(-1,1))\n",
    "essay_word_count_test = normalizer.transform(X_test['essay_word_count'].values.reshape(-1,1))\n",
    "\n",
    "print(\"After vectorizations\")\n",
    "print(essay_word_count_train.shape, y_train.shape)\n",
    "print(essay_word_count_cv.shape, y_cv.shape)\n",
    "print(essay_word_count_test.shape, y_test.shape)\n",
    "\n",
    "print(essay_word_count_train[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code snippet taken from here: https://stackoverflow.com/a/19710648/4084039\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "X_tr = hstack((categories_one_hot_train, sub_categories_one_hot_train, school_state_categories_one_hot_train, \n",
    "               project_grade_categories_one_hot_train, teacher_prefix_categories_one_hot_train, price_train, \n",
    "               quantity_train, prev_projects_train, title_word_count_train, essay_word_count_train, title_bow_train, \n",
    "               text_bow_train)).tocsr()\n",
    "X_te = hstack((categories_one_hot_test, sub_categories_one_hot_test, school_state_categories_one_hot_test,\n",
    "               project_grade_categories_one_hot_test, teacher_prefix_categories_one_hot_test, price_test,\n",
    "               quantity_test, prev_projects_test, title_word_count_test, essay_word_count_test, title_bow_test,\n",
    "               text_bow_test)).tocsr()\n",
    "X_cr = hstack((categories_one_hot_cv, sub_categories_one_hot_cv, school_state_categories_one_hot_cv, \n",
    "               project_grade_categories_one_hot_cv, teacher_prefix_categories_one_hot_cv, price_cv, \n",
    "               quantity_cv, prev_projects_cv, title_word_count_cv, essay_word_count_cv, title_bow_cv, \n",
    "               text_bow_cv)).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Data matrix\n",
      "(81735, 10105) (81735,)\n",
      "(40258, 10105) (40258,)\n",
      "(60087, 10105) (60087,)\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Data matrix\")   #Printing shape of all 3 matrices\n",
    "print(X_tr.shape, y_train.shape)\n",
    "print(X_cr.shape, y_cv.shape)\n",
    "print(X_te.shape, y_test.shape)\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nn BruteForce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_predict(clf, data):\n",
    "    # In case of roc_auc_score(y_true, y_score) the y_score should be probability estimates of the positive class\n",
    "    # not the predicted outputs for the positive class\n",
    "    \n",
    "    #Predicting outputs in batches \n",
    "\n",
    "    y_data_pred = []\n",
    "    tr_loop = data.shape[0] - data.shape[0]%1000\n",
    "    # consider you X_tr shape is 49041, then your cr_loop will be 49041 - 49041%1000 = 49000\n",
    "    # in this for loop we will iterate unti the last 1000 multiplier\n",
    "    for i in range(0, tr_loop, 1000):\n",
    "        y_data_pred.extend(clf.predict_proba(data[i:i+1000])[:,1])\n",
    "    # we will be predicting for the last data points\n",
    "    y_data_pred.extend(clf.predict_proba(data[tr_loop:])[:,1])\n",
    "    \n",
    "    return y_data_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9090909090909091, 0.8181818181818182, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 1/5 [16:08<1:04:32, 968.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8387096774193549, 0.6451612903225806, 0.7096774193548387, 0.7741935483870968, 0.8387096774193549, 0.8064516129032258, 0.7096774193548387, 0.7741935483870968, 0.8709677419354839]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [32:00<48:10, 963.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7843137254901961, 0.7058823529411765, 0.7647058823529411, 0.803921568627451, 0.8627450980392157, 0.8235294117647058, 0.7254901960784313, 0.7647058823529411, 0.8627450980392157]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [47:55<32:01, 960.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8169014084507042, 0.6901408450704225, 0.7887323943661971, 0.8309859154929577, 0.8028169014084507, 0.8450704225352113, 0.7605633802816901, 0.7605633802816901, 0.8450704225352113]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▊                | 4/5 [1:03:42<15:56, 956.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8235294117647058, 0.6823529411764706, 0.7764705882352941, 0.8470588235294118, 0.8117647058823529, 0.8588235294117647, 0.7764705882352941, 0.7529411764705882, 0.8235294117647058]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 5/5 [1:19:25<00:00, 953.11s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\"\"\"\n",
    "y_true : array, shape = [n_samples] or [n_samples, n_classes]\n",
    "True binary labels or binary label indicators.\n",
    "\n",
    "y_score : array, shape = [n_samples] or [n_samples, n_classes]\n",
    "Target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of\n",
    "decisions (as returned by “decision_function” on some classifiers). \n",
    "For binary y_true, y_score is supposed to be the score of the class with greater label.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "train_auc = []\n",
    "cv_auc = []\n",
    "a = []\n",
    "b = []\n",
    "\n",
    "K = [ 11, 31, 51, 71,85]\n",
    "\n",
    "for i in tqdm(K):\n",
    "    neigh  = KNeighborsClassifier(n_neighbors=i)\n",
    "    neigh.fit(X_tr, y_train)\n",
    "\n",
    "    y_train_pred = batch_predict(neigh, X_tr)\n",
    "    print(y_train_pred[1:10])\n",
    "    y_cv_pred = batch_predict(neigh, X_cr)\n",
    "    \n",
    "\n",
    "    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
    "    # not the predicted outputs        \n",
    "    train_auc.append(roc_auc_score(y_train,y_train_pred))\n",
    "    cv_auc.append(roc_auc_score(y_cv, y_cv_pred))\n",
    "    a.append(y_train_pred)\n",
    "    b.append(y_cv_pred)\n",
    "\n",
    "plt.plot(K, train_auc, label='Train AUC')\n",
    "plt.plot(K, cv_auc, label='CV AUC')\n",
    "\n",
    "plt.scatter(K, train_auc, label='Train AUC points')\n",
    "plt.scatter(K, cv_auc, label='CV AUC points')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"K: Hyperparameter\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"ERROR PLOTS of K vs AUC\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-nn using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] n_neighbors=11 ..................................................\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (1670152556,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'decision_function'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-126-9023cccf511f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneigh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtrain_auc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_train_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \"\"\"\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, clf, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m                 \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\neighbors\\classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\neighbors\\base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m                 dist = pairwise_distances(X, self._fit_X, 'euclidean',\n\u001b[1;32m--> 357\u001b[1;33m                                           n_jobs=n_jobs, squared=True)\n\u001b[0m\u001b[0;32m    358\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m                 dist = pairwise_distances(\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;31m# Special case to avoid picklability checks in delayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m     \u001b[1;31m# TODO: in some cases, backend='threading' may be appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[0mYY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m     \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \"\"\"\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"toarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python1\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matmat_pass2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (1670152556,) and data type float64"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "neigh = KNeighborsClassifier()\n",
    "\n",
    "parameters = {'n_neighbors':[11,31,51, 71, 85]}\n",
    "\n",
    "\n",
    "#return_train_score needs to be set True\n",
    "\n",
    "clf = GridSearchCV(neigh, parameters, cv=2 , scoring='roc_auc',return_train_score=True,verbose=2)\n",
    "\n",
    "clf.fit(X_tr, y_train)\n",
    "\n",
    "train_auc= clf.cv_results_['mean_train_score']\n",
    "train_auc_std= clf.cv_results_['std_train_score']\n",
    "cv_auc = clf.cv_results_['mean_test_score'] \n",
    "cv_auc_std= clf.cv_results_['std_test_score']\n",
    "\n",
    "plt.scatter(parameters['n_neighbors'], train_auc, label='Train AUC points')\n",
    "plt.scatter(parameters['n_neighbors'], cv_auc, label='CV AUC points')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"K: hyperparameter\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.title(\"ERROR PLOTS\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
